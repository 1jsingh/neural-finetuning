{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "# misc utility functions\n",
    "from utils.misc import *\n",
    "\n",
    "# load model definitions\n",
    "from utils.models import *\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# ignore convergence warnings from sklearn\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# seaborn\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "\n",
    "# cv2\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "The neural-activation (*in pickle format*) data consists of an organized dictionary with the following entries:\n",
    "\n",
    "* `images_paths`: list containing paths to all the 1960 images\n",
    "* `image_ctg`: numpy array containing class labels from 0 -> 6\n",
    "* `image_splits` : 1960 x 10 numpy array containing 10 80:20 train:val splits used in the paper. Though I generate my own validation splits for computing the sit scores\n",
    "* `features`: 168 dimensional(for multi-unit) neural_features for all the images i.e 1960 x 168 numpy array\n",
    "* `categ_name_map`: dictionary mapping from numeric class label to class name e.g. face, animal etc.\n",
    "\n",
    "The dataset consists of images belonging to 7 classes and 49 object types. The image paths are arranged in an order such that the images belonging to a particular object type are together. There are 40 images per object in the dataset, so images [1 - 40] belong to object 1, images [41 - 80] belong to object 2 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/PLoSCB2014_data_20141216'\n",
    "with open('data/PLoSCB2014_data_20141216/NeuralData_IT_multiunits.pkl','rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Input Images\n",
    "\n",
    "For feeding the cadieu dataset images to the pretrained CNNs, we need to preprocess the images with appropriate reshaping, normalization and other data augmentation steps. In addition, we also need to convert the images to tensors, in order to use pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1960 images ... preprocessed input shape: torch.Size([1960, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# define normalize transform to be used while feeding images to the pretrained CNN\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# combine of transforms in a composition\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(size=(224,224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "# preprocessed input images list\n",
    "X = []\n",
    "\n",
    "for i,img_path in enumerate(data['image_paths']):\n",
    "    img = transform(Image.open(os.path.join(data_path,img_path)))\n",
    "    X.append(img)\n",
    "\n",
    "# convert the list into a tensor\n",
    "X = torch.stack(X)\n",
    "\n",
    "print (\"read {} images ... preprocessed input shape: {}\".format(X.shape[0],X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read neural features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read neural features for 1960 images with shape: (1960, 168)\n"
     ]
    }
   ],
   "source": [
    "neural_features = data['features']\n",
    "print (\"read neural features for {} images with shape: {}\".format(neural_features.shape[0],neural_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datagenerator:\n",
    "    def __init__(self,imgs,neural_features,val_ratio=0.2):\n",
    "        \n",
    "        # get train/val split using val_ratio\n",
    "        self.train_mask,self.val_mask = get_train_val_split_indices(total_num_imgs=imgs.shape[0],val_ratio=val_ratio)\n",
    "        \n",
    "        # get training and validation data\n",
    "        self.imgs_train,self.neural_feat_train = imgs[self.train_mask],neural_features[self.train_mask]\n",
    "        self.imgs_val,self.neural_feat_val = imgs[self.val_mask],neural_features[self.val_mask]\n",
    "        \n",
    "        # number of objects\n",
    "        self.num_obj=49\n",
    "        \n",
    "    \n",
    "    def get_next(self,batch_size=49*2,mode='train'):\n",
    "        \n",
    "        # check if batch size is multiple of self.num_obj\n",
    "        assert batch_size%self.num_obj == 0\n",
    "        \n",
    "        if mode == 'train':\n",
    "            img_split,neural_feat_split = self.imgs_train,self.neural_feat_train\n",
    "        else:\n",
    "            img_split,neural_feat_split = self.imgs_val,self.neural_feat_val\n",
    "        \n",
    "        # compute batch_size ratio\n",
    "        batch_size_ratio = batch_size/img_split.shape[0]\n",
    "        \n",
    "        # sample batch indices\n",
    "        _,batch_mask = get_train_val_split_indices(total_num_imgs=img_split.shape[0],val_ratio=batch_size_ratio)\n",
    "            \n",
    "        # get batch imgs and neural features\n",
    "        img_batch,neural_feat_batch = img_split[batch_mask],neural_feat_split[batch_mask]\n",
    "        \n",
    "        return img_batch,neural_feat_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the pretrained model using RDM loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,device,learning_rate):\n",
    "        # define model and transfer to device\n",
    "        self.model = resnet101_partial().to(device)\n",
    "        \n",
    "        # define optimizer\n",
    "        self.opt = optim.Adam(self.model.parameters(),lr=learning_rate)\n",
    "        \n",
    "        # define datagenerator for sampling batches\n",
    "        self.datagen = Datagenerator(X,neural_features,val_ratio=0.2)\n",
    "        \n",
    "\n",
    "    def train(self,batch_size=49*8,max_train_steps=1000,print_every=10):\n",
    "        # set model to train mode\n",
    "        self.model.train()\n",
    "            \n",
    "        for train_step in range(max_train_steps):\n",
    "\n",
    "            # sample training batch\n",
    "            img_batch,neural_feat_batch = self.datagen.get_next(batch_size=batch_size)\n",
    "            \n",
    "            # transfer the batch to device\n",
    "            img_batch = img_batch.to(device)\n",
    "            \n",
    "            # compute rdm from neural features\n",
    "            neural_rdm = get_rdm(neural_feat_batch)\n",
    "            neural_rdm = torch.from_numpy(neural_rdm).float().to(device)\n",
    "\n",
    "            # get model_features\n",
    "            model_features = self.model(img_batch).squeeze()\n",
    "            # compute model_rdm\n",
    "            model_rdm = get_rdm_tensor(model_features)\n",
    "\n",
    "            # define rdm loss\n",
    "            loss = torch.mean((model_rdm-neural_rdm)**2)\n",
    "\n",
    "            # set optimizer grad to 0\n",
    "            self.opt.zero_grad()\n",
    "            # do backprop on loss\n",
    "            loss.backward()\n",
    "            # perform optimizer step\n",
    "            self.opt.step()\n",
    "            \n",
    "            # print progress after every 'print_every' steps\n",
    "            if train_step%print_every == 0:\n",
    "                \n",
    "                # set model to eval mode\n",
    "                self.model.eval()\n",
    "                \n",
    "                # compute sit for training batch\n",
    "                train_model_features = extract_features(img_batch.detach().cpu(),self.model,batch_size=2)\n",
    "                train_sit_mean,train_sit_std = sit_score(train_model_features,neural_feat_batch,\n",
    "                                                                    num_val_splits=1,val_ratio=1)\n",
    "                \n",
    "                # compute sit for validation dataset\n",
    "                val_model_features = extract_features(self.datagen.imgs_val,self.model)\n",
    "                val_sit_mean,val_sit_std = sit_score(val_model_features,self.datagen.neural_feat_val,\n",
    "                                                                     num_val_splits=1,val_ratio=1)\n",
    "                \n",
    "                # compute linear svm accuracy for validation dataset\n",
    "                model_features = extract_features(agent.datagen.imgs_val,agent.model) \n",
    "                acc_mean,acc_std = linear_svm_score(model_features,\n",
    "                                    data['image_ctg'][agent.datagen.val_mask],agent.datagen.neural_feat_val)\n",
    "                \n",
    "                # set model to train mode\n",
    "                self.model.train()\n",
    "                \n",
    "                # print evaluation metric values\n",
    "                print (\"Train step: {}\\t loss: {:.3f}\\t train_sit: {:.4f} \\t val_sit: {:.4f} \\t acc: {:.4f}\".format(train_step,\n",
    "                                                                loss.item(),train_sit_mean,val_sit_mean,acc_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create agent instance\n",
    "agent = Agent(device,learning_rate=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Model features: linear svm accuracy mean: 0.6373469387755102 \t std: 0.0662467337882354\n"
     ]
    }
   ],
   "source": [
    "# test linear svm accuracy on the validation dataset before training\n",
    "\n",
    "# model features for validation images\n",
    "model_features = extract_features(agent.datagen.imgs_val,agent.model)\n",
    "\n",
    "# get linear svm accuracy for validation model features \n",
    "acc_mean,acc_std = linear_svm_score(model_features,data['image_ctg'][agent.datagen.val_mask],\n",
    "                                    agent.datagen.neural_feat_val)\n",
    "print (\"Validation Model features: linear svm accuracy mean: {} \\t std: {}\".format(acc_mean,acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step: 0\t loss: 0.050\t train_sit: 0.2845 \t val_sit: 0.4074 \t acc: 0.6363\n",
      "Train step: 100\t loss: 0.047\t train_sit: 0.3826 \t val_sit: 0.6319 \t acc: 0.6569\n",
      "Train step: 200\t loss: 0.043\t train_sit: 0.4634 \t val_sit: 0.7121 \t acc: 0.6849\n",
      "Train step: 300\t loss: 0.040\t train_sit: 0.4437 \t val_sit: 0.7539 \t acc: 0.6588\n",
      "Train step: 400\t loss: 0.040\t train_sit: 0.4928 \t val_sit: 0.7729 \t acc: 0.6690\n"
     ]
    }
   ],
   "source": [
    "# train the agent\n",
    "agent.train(batch_size=49*2,max_train_steps=500,print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Model features: linear svm accuracy mean: 0.6759183673469387 \t std: 0.06671191023420812\n"
     ]
    }
   ],
   "source": [
    "# test linear svm accuracy on the validation dataset after training\n",
    "\n",
    "# model features for validation images\n",
    "model_features = extract_features(agent.datagen.imgs_val,agent.model)\n",
    "\n",
    "# get linear svm accuracy for validation model features \n",
    "acc_mean,acc_std = linear_svm_score(model_features,data['image_ctg'][agent.datagen.val_mask],\n",
    "                                    agent.datagen.neural_feat_val)\n",
    "print (\"Validation Model features: linear svm accuracy mean: {} \\t std: {}\".format(acc_mean,acc_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the linear SVM accuracy for model and neural features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Neural features: linear svm accuracy mean: 0.5326530612244896 \t std: 0.04868106302806759\n"
     ]
    }
   ],
   "source": [
    "# get linear svm accuracy for validation set of neural features \n",
    "acc_mean,acc_std = linear_svm_score(agent.datagen.neural_feat_val,data['image_ctg'][agent.datagen.val_mask])\n",
    "print (\"Validation Neural features: linear svm accuracy mean: {} \\t std: {}\".format(acc_mean,acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
