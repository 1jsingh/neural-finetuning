{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# ignore convergence warnings from sklearn\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# seaborn\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "\n",
    "# cv2\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "The neural-activation (*in pickle format*) data consists of an organized dictionary with the following entries:\n",
    "\n",
    "* `images_paths`: list containing paths to all the 1960 images\n",
    "* `image_ctg`: numpy array containing class labels from 0 -> 6\n",
    "* `image_splits` : 1960 x 10 numpy array containing 10 80:20 train:val splits used in the paper. Though I generate my own validation splits for computing the sit scores\n",
    "* `features`: 168 dimensional(for multi-unit) neural_features for all the images i.e 1960 x 168 numpy array\n",
    "* `categ_name_map`: dictionary mapping from numeric class label to class name e.g. face, animal etc.\n",
    "\n",
    "The dataset consists of images belonging to 7 classes and 49 object types. The image paths are arranged in an order such that the images belonging to a particular object type are together. There are 40 images per object in the dataset, so images [1 - 40] belong to object 1, images [41 - 80] belong to object 2 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/PLoSCB2014_data_20141216'\n",
    "with open('data/PLoSCB2014_data_20141216/NeuralData_IT_multiunits.pkl','rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Input Images\n",
    "\n",
    "For feeding the cadieu dataset images to the pretrained CNNs, we need to preprocess the images with appropriate reshaping, normalization and other data augmentation steps. In addition, we also need to convert the images to tensors, in order to use pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1960 images ... preprocessed input shape: torch.Size([1960, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# define normalize transform to be used while feeding images to the pretrained CNN\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# combine of transforms in a composition\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(size=(224,224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "# preprocessed input images list\n",
    "X = []\n",
    "\n",
    "for i,img_path in enumerate(data['image_paths']):\n",
    "    img = transform(Image.open(os.path.join(data_path,img_path)))\n",
    "    X.append(img)\n",
    "\n",
    "# convert the list into a tensor\n",
    "X = torch.stack(X)\n",
    "\n",
    "print (\"read {} images ... preprocessed input shape: {}\".format(X.shape[0],X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained model\n",
    "\n",
    "There are 2 steps to be done here:\n",
    "\n",
    "* Load the pretrained model e.g. alexnet,vgg16,resnet50 etc.\n",
    "* Change it appropriately in order to extract appropriate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7e8c44022c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inception_v3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# transfer model to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/learning/neural-finetuning/utils/loader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# check if model name is valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_byname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# get model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load model definitions\n",
    "from utils.loader import ModelLoader\n",
    "\n",
    "# create ModelLoader instance\n",
    "model_loader = ModelLoader()\n",
    "\n",
    "# define model\n",
    "model = model_loader.load('')\n",
    "\n",
    "# transfer model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# set model to eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of images\n",
    "total_num_images = X.shape[0]\n",
    "\n",
    "# batch size for extracting features\n",
    "batch_size = 8\n",
    "\n",
    "# number of batches\n",
    "num_batches = total_num_images//batch_size\n",
    "\n",
    "# model features\n",
    "model_features = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    # sample batch and put to device\n",
    "    x_batch = X[i*batch_size:(i+1)*batch_size].float().to(device)\n",
    "    \n",
    "    # extract features for the batch\n",
    "    out = model(x_batch)\n",
    "    \n",
    "    # detach output and convert to numpy\n",
    "    out = out.detach().cpu().numpy()\n",
    "    \n",
    "    # store model features for the current batch\n",
    "    model_features.append(out)\n",
    "\n",
    "# concatenate the model features for all batches\n",
    "model_features = np.concatenate(model_features).squeeze()\n",
    "\n",
    "print (\"extracting features for {} images ... model features shape: {}\"\n",
    "                                   .format(model_features.shape[0],model_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(model_features<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('densenet201_feat.pkl','wb') as f:\n",
    "    pickle.dump(model_features,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read neural features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_features = data['features']\n",
    "print (\"read neural features for {} images with shape: {}\".format(neural_features.shape[0],neural_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Representational Dissimilarity Matrix (RDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rdm(features):\n",
    "    # number of objects\n",
    "    num_obj = 49\n",
    "    \n",
    "    # number of images per object\n",
    "    num_imgs_per_obj = int(features.shape[0]/num_obj)\n",
    "    \n",
    "    # compute avg features per object\n",
    "    avg_features = np.zeros((num_obj,features.shape[1]))\n",
    "    for i in range(num_obj):\n",
    "        avg_features[i] = np.mean(features[i*num_imgs_per_obj:(i+1)*num_imgs_per_obj],axis=0)\n",
    "    \n",
    "    # compute correlation matrix\n",
    "    correlation_matrix = np.corrcoef(avg_features)\n",
    "    \n",
    "    # compute rdm matrix\n",
    "    rdm = 1 - correlation_matrix\n",
    "    \n",
    "    return rdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding noise correction to model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_correction(model_features,neural_features):\n",
    "    # noise variance estimation parameters for multiunit\n",
    "    a = 0.14\n",
    "    b = 0.92\n",
    "    \n",
    "    # number of trials\n",
    "    T = 47\n",
    "    \n",
    "    # estimated noise variance\n",
    "    noise_var = np.mean((a*neural_features+b)**2)/T\n",
    "    \n",
    "    # total variance of signal + noise in the neural features\n",
    "    sig_noise_var = np.var(neural_features)\n",
    "    \n",
    "    # expected signal variance for model representations\n",
    "    expected_sig_var = sig_noise_var - noise_var\n",
    "    \n",
    "    # scaling model representations to match expected signal variance\n",
    "    model_features = np.sqrt(expected_sig_var/np.var(model_features))*model_features\n",
    "    \n",
    "    # adding noise to model representations\n",
    "    noise = np.random.randn(model_features.shape[0],model_features.shape[1])\n",
    "    noise = (a*model_features+b)*noise/np.sqrt(T)\n",
    "    model_features += noise\n",
    "    \n",
    "    return model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling different train/validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_split(total_num_imgs=1960,val_ratio=0.2):\n",
    "    # number of objects\n",
    "    num_obj = 49\n",
    "    \n",
    "    # number of images per object\n",
    "    num_imgs_per_obj = int(total_num_imgs/num_obj)\n",
    "    \n",
    "    # number of validation images for each object according to val_ratio\n",
    "    num_val_imgs_per_obj = int(num_imgs_per_obj*val_ratio)\n",
    "    \n",
    "    # compute validation mask s.t. val_mask = 1 for validation images and o/w 0\n",
    "    val_mask = np.zeros(total_num_imgs,dtype=int)\n",
    "    \n",
    "    for obj_count in range(num_obj):\n",
    "        choose = np.random.choice(range(num_imgs_per_obj),num_val_imgs_per_obj,replace=False)\n",
    "        choose += num_imgs_per_obj*obj_count\n",
    "        val_mask[choose] = 1\n",
    "    \n",
    "    # compute train mask as inverse of val_mask\n",
    "    train_mask = (val_mask==0).astype(int)\n",
    "    \n",
    "    return train_mask,val_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Similarity to IT Dissimilarity Matrix (SIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of different validation splits\n",
    "num_val_splits = 1000\n",
    "\n",
    "# store sit scores for different validation splits\n",
    "sit_scores = []\n",
    "\n",
    "for i in range(num_val_splits):\n",
    "    # get validation split\n",
    "    _,val_mask = get_train_val_split(val_ratio=0.2)\n",
    "    \n",
    "    # get model and neural features for validation images\n",
    "    val_model_features = model_features[val_mask==1]\n",
    "    val_neural_features = neural_features[val_mask==1]\n",
    "    \n",
    "    # apply noise correction using validation model and neural features\n",
    "    val_model_features = noise_correction(val_model_features,val_neural_features)\n",
    "    \n",
    "    # compute RDM matrices for neural and model representations\n",
    "    rdm_neural = get_rdm(val_neural_features)\n",
    "    rdm_model = get_rdm(val_model_features)\n",
    "    \n",
    "    # get upper triangular matrix values for model and neural rdm\n",
    "    iu1 = np.triu_indices(49,k=1)\n",
    "    rdm_neural_triu = rdm_neural[iu1]\n",
    "    rdm_model_triu = rdm_model[iu1]\n",
    "    \n",
    "    # compute sit score and store the result\n",
    "    sit_score = scipy.stats.spearmanr(rdm_model_triu,rdm_neural_triu).correlation\n",
    "    sit_scores.append(sit_score)\n",
    "\n",
    "# print the mean and standard deviation of sit scores\n",
    "print (\"sit_mean: {}\\t sit_std: {}\".format(np.mean(sit_scores),np.std(sit_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM accuracy score\n",
    "\n",
    "In order to see how good any set of features is, we compute the Linear SVM accuracy obtained for the classification task on the cadieu dataset (7 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svm_score(features,labels,neural_features=None,num_subsampled_feat=168):\n",
    "    \n",
    "    # number of validation splits\n",
    "    num_val_splits = 10\n",
    "    \n",
    "    # accuracy scores\n",
    "    acc_scores = []\n",
    "    \n",
    "    # apply noise correction\n",
    "    if neural_features is not None:\n",
    "        features = noise_correction(features,neural_features)\n",
    "        \n",
    "    for _ in range(num_val_splits):\n",
    "        # get train:test split with ratio 80:20\n",
    "        train_mask,test_mask = get_train_val_split(val_ratio=0.2)\n",
    "\n",
    "        # get training and test datasets\n",
    "        X_train,y_train = features[train_mask==1],labels[train_mask==1]\n",
    "        X_test,y_test = features[test_mask==1],labels[test_mask==1]\n",
    "        \n",
    "        # get train:val split with ratio 80:20\n",
    "        train_mask,val_mask = get_train_val_split(X_train.shape[0],val_ratio=0.2)\n",
    "\n",
    "        # get training and val datasets\n",
    "        X_val,y_val = X_train[val_mask==1],y_train[val_mask==1]\n",
    "        X_train,y_train = X_train[train_mask==1],y_train[train_mask==1]\n",
    "        \n",
    "        # number of feature subsamples\n",
    "        num_feat_samples = 10\n",
    "        \n",
    "        for i in range(num_feat_samples):\n",
    "            # get a subsample\n",
    "            feat_subsample = np.random.choice(range(features.shape[1]),num_subsampled_feat,replace=False)\n",
    "            \n",
    "            # get subsampled train,validation and test datasets\n",
    "            X_train_subsample = X_train[:,feat_subsample]\n",
    "            X_val_subsample = X_val[:,feat_subsample]\n",
    "            X_test_subsample = X_test[:,feat_subsample]\n",
    "            \n",
    "            # range to sample regularization parameter C\n",
    "            C_range = [1e-3,1e-2,1e-1,1e0,1e1,1e2]\n",
    "            \n",
    "            # store val acc scores to choose the best C\n",
    "            val_acc_scores = []\n",
    "            \n",
    "            for C in C_range:\n",
    "                # linear SVM classifier\n",
    "                clf = LinearSVC(C=C,max_iter=1000)\n",
    "\n",
    "                # fit training data\n",
    "                clf.fit(X_train_subsample,y_train)\n",
    "\n",
    "                # get mean accuracy on validation data\n",
    "                val_acc = clf.score(X_val_subsample,y_val)\n",
    "                \n",
    "                # store val_acc\n",
    "                val_acc_scores.append(val_acc)\n",
    "            \n",
    "            # choose best C\n",
    "            best_C = C_range[np.argmax(val_acc_scores)]\n",
    "            \n",
    "            # linear SVM classifier for best C\n",
    "            clf = LinearSVC(C=best_C,max_iter=5000)\n",
    "\n",
    "            # fit training data\n",
    "            clf.fit(X_train_subsample,y_train)\n",
    "            \n",
    "            # get mean accuracy on test data\n",
    "            test_acc = clf.score(X_test_subsample,y_test)\n",
    "            \n",
    "            # store accuracy\n",
    "            acc_scores.append(test_acc)\n",
    "    \n",
    "    return np.mean(acc_scores),np.std(acc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get linear svm accuracy for model features \n",
    "acc_mean,acc_std = linear_svm_score(model_features,data['image_ctg'],neural_features)\n",
    "print (\"Model features: linear svm accuracy mean: {} \\t std: {}\".format(acc_mean,acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get linear svm accuracy for IT neural features \n",
    "acc_mean,acc_std = linear_svm_score(neural_features,data['image_ctg'])\n",
    "print (\"Neural features: linear svm accuracy mean: {} \\t std: {}\".format(acc_mean,acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/PLoSCB2014_data_20141216'\n",
    "with open('data/PLoSCB2014_data_20141216/NeuralData_V4_multiunits.pkl','rb') as f:\n",
    "    data_ = pickle.load(f)\n",
    "    \n",
    "v4_features = data_['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get linear svm accuracy for v4 neural features \n",
    "acc_mean,acc_std = linear_svm_score(v4_features,data['image_ctg'],num_subsampled_feat=128)\n",
    "print (\"Neural features: linear svm accuracy mean: {} \\t std: {}\".format(acc_mean,acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
