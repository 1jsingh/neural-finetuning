{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# ignore convergence warnings from sklearn\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# seaborn\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "\n",
    "# cv2\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "The neural-activation (*in pickle format*) data consists of an organized dictionary with the following entries:\n",
    "\n",
    "* `images_paths`: list containing paths to all the 1960 images\n",
    "* `image_ctg`: numpy array containing class labels from 0 -> 6\n",
    "* `image_splits` : 1960 x 10 numpy array containing 10 80:20 train:val splits used in the paper. Though I generate my own validation splits for computing the sit scores\n",
    "* `features`: 168 dimensional(for multi-unit) neural_features for all the images i.e 1960 x 168 numpy array\n",
    "* `categ_name_map`: dictionary mapping from numeric class label to class name e.g. face, animal etc.\n",
    "\n",
    "The dataset consists of images belonging to 7 classes and 49 object types. The image paths are arranged in an order such that the images belonging to a particular object type are together. There are 40 images per object in the dataset, so images [1 - 40] belong to object 1, images [41 - 80] belong to object 2 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/PLoSCB2014_data_20141216'\n",
    "with open('data/PLoSCB2014_data_20141216/NeuralData_IT_multiunits.pkl','rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Input Images\n",
    "\n",
    "For feeding the cadieu dataset images to the pretrained CNNs, we need to preprocess the images with appropriate reshaping, normalization and other data augmentation steps. In addition, we also need to convert the images to tensors, in order to use pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1960 images ... preprocessed input shape: torch.Size([1960, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# define normalize transform to be used while feeding images to the pretrained CNN\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# combine of transforms in a composition\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(size=(224,224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "# preprocessed input images list\n",
    "X = []\n",
    "\n",
    "for i,img_path in enumerate(data['image_paths']):\n",
    "    img = transform(Image.open(os.path.join(data_path,img_path)))\n",
    "    X.append(img)\n",
    "\n",
    "# convert the list into a tensor\n",
    "X = torch.stack(X)\n",
    "\n",
    "print (\"read {} images ... preprocessed input shape: {}\".format(X.shape[0],X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained model\n",
    "\n",
    "There are 2 steps to be done here:\n",
    "\n",
    "* Load the pretrained model e.g. alexnet,vgg16,resnet50 etc.\n",
    "* Change it appropriately in order to extract appropriate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model definitions\n",
    "from utils.models import *\n",
    "\n",
    "# define model\n",
    "model = Alexnet_partial()\n",
    "\n",
    "# transfer model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# set model to eval mode\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read neural features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read neural features for 1960 images with shape: (1960, 168)\n"
     ]
    }
   ],
   "source": [
    "neural_features = data['features']\n",
    "print (\"read neural features for {} images with shape: {}\".format(neural_features.shape[0],neural_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(X):\n",
    "    '''\n",
    "    Input:\n",
    "        X: num_obj,D tensor\n",
    "    \n",
    "    Output:\n",
    "        rdm: num_obj,num_obj tensor\n",
    "    '''\n",
    "    # make X zero mean\n",
    "    X_ = X - torch.mean(X,dim=0)\n",
    "    \n",
    "    # compute Covariance matrix\n",
    "    cov_matrix = torch.matmul(X_.transpose(0,1),X_)/X.shape[0]\n",
    "    \n",
    "    # get standard deviations for each of the dimensions\n",
    "    std_devs = torch.std(X,dim=0,unbiased=False).unsqueeze(dim=1)\n",
    "    \n",
    "    # get normalizing standard deviation product matrix\n",
    "    std_matrix = torch.matmul(std_devs,std_devs.transpose(0,1))\n",
    "    \n",
    "    # compute correlation matrix\n",
    "    corr_matrix = torch.div(cov_matrix,std_matrix)\n",
    "    \n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Representational Dissimilarity Matrix (RDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rdm_tensor(features):\n",
    "    '''\n",
    "    Input:\n",
    "        features: N,D tensor\n",
    "    \n",
    "    Output:\n",
    "        rdm: num_obj,num_obj tensor\n",
    "    '''\n",
    "    \n",
    "    # number of objects\n",
    "    num_obj = 49\n",
    "    \n",
    "    # number of images per object\n",
    "    num_imgs_per_obj = int(features.shape[0]/num_obj)\n",
    "    \n",
    "    # compute avg features per object\n",
    "    avg_features = torch.zeros((num_obj,features.shape[1])).float().to(device)\n",
    "    for i in range(num_obj):\n",
    "        avg_features[i] = torch.mean(features[i*num_imgs_per_obj:(i+1)*num_imgs_per_obj],dim=0)\n",
    "    \n",
    "    # compute correlation matrix\n",
    "    correlation_matrix = get_corr_matrix(avg_features)\n",
    "    \n",
    "    # compute rdm matrix\n",
    "    rdm = 1 - correlation_matrix\n",
    "    \n",
    "    return rdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling different train/validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_split(total_num_imgs=1960,val_ratio=0.2):\n",
    "    # number of objects\n",
    "    num_obj = 49\n",
    "    \n",
    "    # number of images per object\n",
    "    num_imgs_per_obj = int(total_num_imgs/num_obj)\n",
    "    \n",
    "    # number of validation images for each object according to val_ratio\n",
    "    num_val_imgs_per_obj = int(num_imgs_per_obj*val_ratio)\n",
    "    \n",
    "    # compute validation mask s.t. val_mask = 1 for validation images and o/w 0\n",
    "    val_mask = np.zeros(total_num_imgs,dtype=int)\n",
    "    \n",
    "    for obj_count in range(num_obj):\n",
    "        choose = np.random.choice(range(num_imgs_per_obj),num_val_imgs_per_obj,replace=False)\n",
    "        choose += num_imgs_per_obj*obj_count\n",
    "        val_mask[choose] = 1\n",
    "    \n",
    "    # compute train mask as inverse of val_mask\n",
    "    train_mask = (val_mask==0).astype(int)\n",
    "    \n",
    "    return train_mask,val_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Similarity to IT Dissimilarity Matrix (SIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sit_mean: 0.4795214836397871\t sit_std: 0.029482496433147307\n"
     ]
    }
   ],
   "source": [
    "# number of different validation splits\n",
    "num_val_splits = 1000\n",
    "\n",
    "# store sit scores for different validation splits\n",
    "sit_scores = []\n",
    "\n",
    "for i in range(num_val_splits):\n",
    "    # get validation split\n",
    "    _,val_mask = get_train_val_split(val_ratio=0.2)\n",
    "    \n",
    "    # get model and neural features for validation images\n",
    "    val_model_features = model_features[val_mask==1]\n",
    "    val_neural_features = neural_features[val_mask==1]\n",
    "    \n",
    "    # apply noise correction using validation model and neural features\n",
    "    val_model_features = noise_correction(val_model_features,val_neural_features)\n",
    "    \n",
    "    # compute RDM matrices for neural and model representations\n",
    "    rdm_neural = get_rdm(val_neural_features)\n",
    "    rdm_model = get_rdm(val_model_features)\n",
    "    \n",
    "    # get upper triangular matrix values for model and neural rdm\n",
    "    iu1 = np.triu_indices(49,k=1)\n",
    "    rdm_neural_triu = rdm_neural[iu1]\n",
    "    rdm_model_triu = rdm_model[iu1]\n",
    "    \n",
    "    # compute sit score and store the result\n",
    "    sit_score = scipy.stats.spearmanr(rdm_model_triu,rdm_neural_triu).correlation\n",
    "    sit_scores.append(sit_score)\n",
    "\n",
    "# print the mean and standard deviation of sit scores\n",
    "print (\"sit_mean: {}\\t sit_std: {}\".format(np.mean(sit_scores),np.std(sit_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM accuracy score\n",
    "\n",
    "In order to see how good any set of features is, we compute the Linear SVM accuracy obtained for the classification task on the cadieu dataset (7 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svm_score(features,labels,neural_features=None,num_subsampled_feat=168):\n",
    "    \n",
    "    # number of validation splits\n",
    "    num_val_splits = 10\n",
    "    \n",
    "    # accuracy scores\n",
    "    acc_scores = []\n",
    "    \n",
    "    # apply noise correction\n",
    "    if neural_features is not None:\n",
    "        features = noise_correction(features,neural_features)\n",
    "        \n",
    "    for _ in range(num_val_splits):\n",
    "        # get train:test split with ratio 80:20\n",
    "        train_mask,test_mask = get_train_val_split(val_ratio=0.2)\n",
    "\n",
    "        # get training and test datasets\n",
    "        X_train,y_train = features[train_mask==1],labels[train_mask==1]\n",
    "        X_test,y_test = features[test_mask==1],labels[test_mask==1]\n",
    "        \n",
    "        # get train:val split with ratio 80:20\n",
    "        train_mask,val_mask = get_train_val_split(X_train.shape[0],val_ratio=0.2)\n",
    "\n",
    "        # get training and val datasets\n",
    "        X_val,y_val = X_train[val_mask==1],y_train[val_mask==1]\n",
    "        X_train,y_train = X_train[train_mask==1],y_train[train_mask==1]\n",
    "        \n",
    "        # number of feature subsamples\n",
    "        num_feat_samples = 10\n",
    "        \n",
    "        for i in range(num_feat_samples):\n",
    "            # get a subsample\n",
    "            feat_subsample = np.random.choice(range(features.shape[1]),num_subsampled_feat,replace=False)\n",
    "            \n",
    "            # get subsampled train,validation and test datasets\n",
    "            X_train_subsample = X_train[:,feat_subsample]\n",
    "            X_val_subsample = X_val[:,feat_subsample]\n",
    "            X_test_subsample = X_test[:,feat_subsample]\n",
    "            \n",
    "            # range to sample regularization parameter C\n",
    "            C_range = [1e-3,1e-2,1e-1,1e0,1e1,1e2]\n",
    "            \n",
    "            # store val acc scores to choose the best C\n",
    "            val_acc_scores = []\n",
    "            \n",
    "            for C in C_range:\n",
    "                # linear SVM classifier\n",
    "                clf = LinearSVC(C=C,max_iter=1000)\n",
    "\n",
    "                # fit training data\n",
    "                clf.fit(X_train_subsample,y_train)\n",
    "\n",
    "                # get mean accuracy on validation data\n",
    "                val_acc = clf.score(X_val_subsample,y_val)\n",
    "                \n",
    "                # store val_acc\n",
    "                val_acc_scores.append(val_acc)\n",
    "            \n",
    "            # choose best C\n",
    "            best_C = C_range[np.argmax(val_acc_scores)]\n",
    "            \n",
    "            # linear SVM classifier for best C\n",
    "            clf = LinearSVC(C=best_C,max_iter=5000)\n",
    "\n",
    "            # fit training data\n",
    "            clf.fit(X_train_subsample,y_train)\n",
    "            \n",
    "            # get mean accuracy on test data\n",
    "            test_acc = clf.score(X_test_subsample,y_test)\n",
    "            \n",
    "            # store accuracy\n",
    "            acc_scores.append(test_acc)\n",
    "    \n",
    "    return np.mean(acc_scores),np.std(acc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model features: linear svm accuracy mean: 0.7794897959183673 \t std: 0.0199577855192442\n"
     ]
    }
   ],
   "source": [
    "# get linear svm accuracy for model features \n",
    "acc_mean,acc_std = linear_svm_score(model_features,data['image_ctg'],neural_features)\n",
    "print (\"Model features: linear svm accuracy mean: {} \\t std: {}\".format(acc_mean,acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get linear svm accuracy for IT neural features \n",
    "acc_mean,acc_std = linear_svm_score(neural_features,data['image_ctg'])\n",
    "print (\"Neural features: linear svm accuracy mean: {} \\t std: {}\".format(acc_mean,acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/PLoSCB2014_data_20141216'\n",
    "with open('data/PLoSCB2014_data_20141216/NeuralData_V4_multiunits.pkl','rb') as f:\n",
    "    data_ = pickle.load(f)\n",
    "    \n",
    "v4_features = data_['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural features: linear svm accuracy mean: 0.3187244897959184 \t std: 0.01700526353579089\n"
     ]
    }
   ],
   "source": [
    "# get linear svm accuracy for v4 neural features \n",
    "acc_mean,acc_std = linear_svm_score(v4_features,data['image_ctg'],num_subsampled_feat=128)\n",
    "print (\"Neural features: linear svm accuracy mean: {} \\t std: {}\".format(acc_mean,acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv3",
   "language": "python",
   "name": "cv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
